{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Credit card fraud is a significant problem in the financial industry, resulting in billions of dollars in losses annually. This project demonstrates the application of machine learning techniques to detect fraudulent transactions from a highly imbalanced dataset.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "Perform exploratory data analysis on credit card transaction data, handle class imbalance using SMOTE and undersampling, build and evaluate multiple classification models, and compare performance using appropriate metrics for imbalanced data.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset contains transactions made by European cardholders in September 2013. It presents transactions that occurred over two days, with 492 frauds out of 284,807 transactions (0.172% fraud rate).\n",
    "\n",
    "**Features** - `Time` (seconds elapsed between transactions), `V1-V28` (PCA-transformed features, anonymized), `Amount` (transaction amount), `Class` (target - 0 for legitimate, 1 for fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Handling imbalanced data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score, \n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/creditcard.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset Shape - {df.shape}\")\n",
    "print(f\"Total Transactions - {len(df):,}\")\n",
    "print(f\"\\nFeatures - {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and missing values\n",
    "print(\"Data Types\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(f\"\\nMissing Values - {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "class_counts = df['Class'].value_counts()\n",
    "class_percentages = df['Class'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Class Distribution\")\n",
    "print(f\"Legitimate (0) - {class_counts[0]:,} transactions ({class_percentages[0]:.3f}%)\")\n",
    "print(f\"Fraudulent (1) - {class_counts[1]:,} transactions ({class_percentages[1]:.3f}%)\")\n",
    "print(f\"\\nImbalance Ratio - 1:{class_counts[0]//class_counts[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[0].bar(['Legitimate', 'Fraud'], class_counts.values, color=colors, edgecolor='black')\n",
    "axes[0].set_ylabel('Number of Transactions', fontsize=12)\n",
    "axes[0].set_title('Class Distribution - Count', fontsize=14, fontweight='bold')\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    axes[0].text(i, v + 5000, f'{v:,}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(class_counts.values, labels=['Legitimate', 'Fraud'], autopct='%1.3f%%',\n",
    "            colors=colors, explode=(0, 0.1), shadow=True, startangle=90)\n",
    "axes[1].set_title('Class Distribution - Percentage', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Transaction Amount Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction amount statistics by class\n",
    "print(\"Transaction Amount Statistics\")\n",
    "print(\"\\nLegitimate Transactions\")\n",
    "print(df[df['Class'] == 0]['Amount'].describe())\n",
    "print(\"\\nFraudulent Transactions\")\n",
    "print(df[df['Class'] == 1]['Amount'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transaction amounts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution of amounts\n",
    "axes[0].hist(df[df['Class'] == 0]['Amount'], bins=50, alpha=0.7, label='Legitimate', color='#2ecc71')\n",
    "axes[0].hist(df[df['Class'] == 1]['Amount'], bins=50, alpha=0.7, label='Fraud', color='#e74c3c')\n",
    "axes[0].set_xlabel('Transaction Amount ($)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Transaction Amounts', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlim(0, 500)\n",
    "\n",
    "# Box plot\n",
    "df_plot = df[['Amount', 'Class']].copy()\n",
    "df_plot['Class'] = df_plot['Class'].map({0: 'Legitimate', 1: 'Fraud'})\n",
    "sns.boxplot(x='Class', y='Amount', data=df_plot, ax=axes[1], palette=colors)\n",
    "axes[1].set_ylabel('Transaction Amount ($)', fontsize=12)\n",
    "axes[1].set_title('Transaction Amount by Class', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim(0, 500)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/amount_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time to hours\n",
    "df['Hour'] = (df['Time'] / 3600) % 24\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Transactions over time\n",
    "axes[0].hist(df[df['Class'] == 0]['Hour'], bins=24, alpha=0.7, label='Legitimate', color='#2ecc71', density=True)\n",
    "axes[0].hist(df[df['Class'] == 1]['Hour'], bins=24, alpha=0.7, label='Fraud', color='#e74c3c', density=True)\n",
    "axes[0].set_xlabel('Hour of Day', fontsize=12)\n",
    "axes[0].set_ylabel('Density', fontsize=12)\n",
    "axes[0].set_title('Transaction Distribution Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Fraud rate by hour\n",
    "hourly_fraud = df.groupby(df['Hour'].astype(int))['Class'].mean() * 100\n",
    "axes[1].bar(hourly_fraud.index, hourly_fraud.values, color='#3498db', edgecolor='black')\n",
    "axes[1].set_xlabel('Hour of Day', fontsize=12)\n",
    "axes[1].set_ylabel('Fraud Rate (%)', fontsize=12)\n",
    "axes[1].set_title('Fraud Rate by Hour', fontsize=14, fontweight='bold')\n",
    "axes[1].axhline(y=df['Class'].mean()*100, color='red', linestyle='--', label='Average Fraud Rate')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/time_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target variable\n",
    "correlations = df.drop('Hour', axis=1).corr()['Class'].sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "colors = ['#e74c3c' if x > 0 else '#3498db' for x in correlations.values[1:]]\n",
    "correlations[1:].plot(kind='barh', color=colors, ax=ax)\n",
    "ax.set_xlabel('Correlation Coefficient', fontsize=12)\n",
    "ax.set_title('Feature Correlation with Fraud', fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/feature_correlation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top correlated features visualization\n",
    "top_positive = ['V11', 'V4', 'V2']\n",
    "top_negative = ['V14', 'V12', 'V10']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for idx, feature in enumerate(top_negative):\n",
    "    ax = axes[0, idx]\n",
    "    sns.kdeplot(data=df, x=feature, hue='Class', ax=ax, palette=colors, fill=True, alpha=0.5)\n",
    "    ax.set_title(f'{feature} Distribution - Negative Correlation', fontsize=12, fontweight='bold')\n",
    "\n",
    "for idx, feature in enumerate(top_positive):\n",
    "    ax = axes[1, idx]\n",
    "    sns.kdeplot(data=df, x=feature, hue='Class', ax=ax, palette=colors, fill=True, alpha=0.5)\n",
    "    ax.set_title(f'{feature} Distribution - Positive Correlation', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/top_features_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Hour column (was created for analysis)\n",
    "df = df.drop('Hour', axis=1)\n",
    "\n",
    "# Scale Amount and Time features using RobustScaler (handles outliers better)\n",
    "scaler = RobustScaler()\n",
    "df['Amount_scaled'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "df['Time_scaled'] = scaler.fit_transform(df['Time'].values.reshape(-1, 1))\n",
    "\n",
    "# Drop original Amount and Time\n",
    "df = df.drop(['Amount', 'Time'], axis=1)\n",
    "\n",
    "print(f\"Preprocessed dataset shape - {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "print(f\"Features shape - {X.shape}\")\n",
    "print(f\"Target shape - {y.shape}\")\n",
    "print(f\"\\nTarget distribution\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (stratified to maintain class ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set - {X_train.shape[0]:,} samples\")\n",
    "print(f\"Test set - {X_test.shape[0]:,} samples\")\n",
    "print(f\"\\nTraining set class distribution\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest set class distribution\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to training data only\n",
    "smote = SMOTE(random_state=42, sampling_strategy=0.5)  # Create fraud samples = 50% of legitimate\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Original training set shape - {X_train.shape}\")\n",
    "print(f\"SMOTE training set shape - {X_train_smote.shape}\")\n",
    "print(f\"\\nOriginal class distribution\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nSMOTE class distribution\")\n",
    "print(pd.Series(y_train_smote).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply undersampling to training data\n",
    "undersampler = RandomUnderSampler(random_state=42, sampling_strategy=1.0)  # Equal ratio\n",
    "X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Undersampled training set shape - {X_train_under.shape}\")\n",
    "print(f\"\\nUndersampled class distribution\")\n",
    "print(pd.Series(y_train_under).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate model performance with multiple metrics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : trained model object\n",
    "    X_test : test features\n",
    "    y_test : test labels\n",
    "    model_name : string name for the model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict : dictionary containing all evaluation metrics\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'Avg Precision': average_precision_score(y_test, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    return metrics, y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred, model_name, ax):\n",
    "    \"\"\"Plot confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Legitimate', 'Fraud'],\n",
    "                yticklabels=['Legitimate', 'Fraud'])\n",
    "    ax.set_xlabel('Predicted', fontsize=11)\n",
    "    ax.set_ylabel('Actual', fontsize=11)\n",
    "    ax.set_title(f'{model_name}', fontsize=12, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate each model on SMOTE data\n",
    "print(\"Training models on SMOTE-resampled data...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics, y_pred, y_pred_proba = evaluate_model(model, X_test, y_test, name)\n",
    "    results.append(metrics)\n",
    "    predictions[name] = {'y_pred': y_pred, 'y_pred_proba': y_pred_proba}\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"-\" * 40)\n",
    "    print(classification_report(y_test, y_pred, target_names=['Legitimate', 'Fraud']))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.set_index('Model')\n",
    "\n",
    "# Format as percentages\n",
    "results_display = results_df.copy()\n",
    "for col in results_display.columns:\n",
    "    results_display[col] = results_display[col].apply(lambda x: f'{x:.4f}')\n",
    "\n",
    "print(\"Model Performance Comparison\")\n",
    "print(\"=\" * 80)\n",
    "results_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Metrics comparison\n",
    "metrics_to_plot = ['Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "results_df[metrics_to_plot].plot(kind='bar', ax=axes[0], rot=0, width=0.8)\n",
    "axes[0].set_ylabel('Score', fontsize=12)\n",
    "axes[0].set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].set_ylim(0, 1.1)\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt='%.3f', fontsize=8)\n",
    "\n",
    "# ROC-AUC comparison\n",
    "colors_bar = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "results_df['ROC-AUC'].plot(kind='bar', ax=axes[1], color=colors_bar, rot=0)\n",
    "axes[1].set_ylabel('ROC-AUC Score', fontsize=12)\n",
    "axes[1].set_title('ROC-AUC Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim(0.9, 1.0)\n",
    "for i, v in enumerate(results_df['ROC-AUC'].values):\n",
    "    axes[1].text(i, v + 0.002, f'{v:.4f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, (name, preds) in enumerate(predictions.items()):\n",
    "    plot_confusion_matrix(y_test, preds['y_pred'], name, axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors_roc = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "\n",
    "for idx, (name, preds) in enumerate(predictions.items()):\n",
    "    fpr, tpr, _ = roc_curve(y_test, preds['y_pred_proba'])\n",
    "    auc_score = roc_auc_score(y_test, preds['y_pred_proba'])\n",
    "    ax.plot(fpr, tpr, color=colors_roc[idx], linewidth=2,\n",
    "            label=f'{name} (AUC = {auc_score:.4f})')\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall curves\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for idx, (name, preds) in enumerate(predictions.items()):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, preds['y_pred_proba'])\n",
    "    ap_score = average_precision_score(y_test, preds['y_pred_proba'])\n",
    "    ax.plot(recall, precision, color=colors_roc[idx], linewidth=2,\n",
    "            label=f'{name} (AP = {ap_score:.4f})')\n",
    "\n",
    "# Baseline (proportion of positive class)\n",
    "baseline = y_test.sum() / len(y_test)\n",
    "ax.axhline(y=baseline, color='gray', linestyle='--', linewidth=1, label=f'Baseline ({baseline:.4f})')\n",
    "\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Precision', fontsize=12)\n",
    "ax.set_title('Precision-Recall Curves', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/precision_recall_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Feature Importance - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from Random Forest\n",
    "rf_model = models['Random Forest']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "top_features = feature_importance.head(15)\n",
    "colors_feat = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(top_features)))\n",
    "ax.barh(top_features['Feature'], top_features['Importance'], color=colors_feat)\n",
    "ax.set_xlabel('Feature Importance', fontsize=12)\n",
    "ax.set_title('Top 15 Most Important Features - Random Forest', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 80)\n",
    "print(\"CREDIT CARD FRAUD DETECTION - FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. DATASET CHARACTERISTICS\")\n",
    "print(f\"   Total transactions - 284,807\")\n",
    "print(f\"   Fraudulent transactions - 492 (0.172%)\")\n",
    "print(f\"   Imbalance ratio - 1:578\")\n",
    "\n",
    "print(\"\\n2. PREPROCESSING\")\n",
    "print(\"   Applied RobustScaler to Amount and Time features\")\n",
    "print(\"   Used SMOTE for handling class imbalance\")\n",
    "print(\"   80-20 train-test split with stratification\")\n",
    "\n",
    "print(\"\\n3. MODEL PERFORMANCE\")\n",
    "print(results_df.to_string())\n",
    "\n",
    "best_model = results_df['F1-Score'].idxmax()\n",
    "print(f\"\\n4. BEST PERFORMING MODEL - {best_model}\")\n",
    "print(f\"   F1-Score - {results_df.loc[best_model, 'F1-Score']:.4f}\")\n",
    "print(f\"   ROC-AUC - {results_df.loc[best_model, 'ROC-AUC']:.4f}\")\n",
    "print(f\"   Recall - {results_df.loc[best_model, 'Recall']:.4f}\")\n",
    "\n",
    "print(\"\\n5. KEY FINDINGS\")\n",
    "print(\"   V14, V12, and V10 are the most negatively correlated features with fraud\")\n",
    "print(\"   V17, V14, and V12 are the most important features for prediction\")\n",
    "print(\"   SMOTE effectively addresses class imbalance\")\n",
    "print(\"   Ensemble methods outperform Logistic Regression\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Future Improvements\n",
    "\n",
    "**Hyperparameter Tuning** - Use GridSearchCV or RandomizedSearchCV to optimize model parameters\n",
    "\n",
    "**Additional Models** - Test LightGBM, CatBoost, or Neural Networks\n",
    "\n",
    "**Feature Engineering** - Create new features from existing ones such as transaction velocity\n",
    "\n",
    "**Ensemble Methods** - Combine multiple models using stacking or voting classifiers\n",
    "\n",
    "**Threshold Optimization** - Adjust classification threshold based on business requirements\n",
    "\n",
    "**Cost-Sensitive Learning** - Incorporate different costs for false positives vs false negatives\n",
    "\n",
    "**Real-time Detection** - Implement streaming pipeline for real-time fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "import joblib\n",
    "\n",
    "best_model_obj = models[best_model]\n",
    "joblib.dump(best_model_obj, '../models/best_fraud_detector.pkl')\n",
    "print(f\"Best model ({best_model}) saved to '../models/best_fraud_detector.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
